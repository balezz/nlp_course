{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae02171",
   "metadata": {},
   "source": [
    "# Тема 3. Языковые модели и тематическое моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b344e",
   "metadata": {},
   "source": [
    "1) N-граммы  \n",
    "2) Языковые модели и перплексия  \n",
    "3) Тематическое моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d185d39",
   "metadata": {},
   "source": [
    "### 1) N-граммы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c8e903",
   "metadata": {},
   "source": [
    "На прошлом занятии мы познакомились с базовыми техниками работы с текстами, в т.ч. токенизацией на отдельные слова. Однако в естественных языках существуют устойчивые комбинации слов (словосочетания), несущие в себе собственный смысл, например ice cream или доброе утро.  \n",
    "**Коллокация (collocation)** — словосочетание, имеющее признаки синтаксически и семантически целостной единицы.\n",
    "К коллокациям также обычно причисляют составные топонимы, антропонимы и другие часто совместно употребляемые именования (например, крейсер «Аврора», завод имени Кирова).\n",
    "В NLP пары слов называются биграммами, тройки — триграммами, и т.д..  \n",
    "**N-грамма** — это последовательность, содержащая до n элементов, которые были извлечены из последовательности этих элементов, обычно строки. Использование n-грамм позволяет машине знать о таких словах, как ice cream, а также о составляющих его ice и cream. \n",
    "В общем случае элементами n-граммы могут быть буквы, слоги, слова или даже символы, такие как A, T, G и C, используемые для представления последовательности ДНК. В дальнейшем под N-граммой мы будем понимать только комбинацию слов.  \n",
    "\n",
    "Зачем нужны на n-граммы? При преобразовании в OneHot вектор слов последовательность токенов теряет часть смысла, заключенного в порядке этих слов. Если расширить концепцию токена на токены из нескольких слов (n-грамм), то можно сохранить значительную долю смысла, заключенного в порядке слов в этих высказываниях. Например, слово not, меняющее смысл на обратный, останется рядом с соседними словами, где и должно быть. Без n-граммовой токенизации такое слово болталось бы по разным позициям, а его смысл связывался бы со всем предложением или документом, а не с соседними словами. Биграмма was not сохраняет гораздо больше смысла отдельных слов was и not, чем соответствующие однограммы в векторе OneHot. Таким образом, сохраняется небольшая часть контекста слова. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d56d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Thomas', 'Jefferson')\n",
      "('Jefferson', 'began')\n",
      "('began', 'building')\n",
      "('building', 'Monticello')\n",
      "('Monticello', 'at')\n",
      "('at', 'the')\n",
      "('the', 'age')\n",
      "('age', 'of')\n",
      "('of', '26')\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "sent = 'Thomas Jefferson began building Monticello at the age of 26'\n",
    "tokens_2 = ngrams(sent.split(), 2)\n",
    "for t in tokens_2:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf25330",
   "metadata": {},
   "source": [
    "Можно предположить, что токен \"Thomas Jefferson\" будет часто встречаться во многих документах, а \"of 26\" или \"Jefferson began\" редко. \n",
    "Большинство биграмм довольно редки, не говоря уже о 3- и 4-граммах. \n",
    "Необходимо использовать статистику частотностей n-грамм, и оставлять только часто встречающиеся. \n",
    "Как правило, слишком редкие n-граммы отфильтровываются, а часто встречающиеся включаются в словарь наравне со словами. \n",
    "\n",
    "Противоположная проблема — биграмма \"at the\" из примера. \n",
    "Это нередкая комбинация слов, но она непригодна для различения смысла документа. \n",
    "Подобно словам и другим токенам, слишком часто встречающиеся n-граммы отфильтровываются. \n",
    "Токены или n-граммы, встречающиеся в более чем 25 % всех документов в корпусе, обычно игнорируются. \n",
    "Использование подобных фильтров полезно как в отношении n-грамм, так и для отдельных токенов.\n",
    "\n",
    "Для оценки частотности слов используется техника Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc9b96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words:\n",
      "Counter({'likes': 2, 'movies': 2, 'John': 1, 'to': 1, 'watch': 1, ',': 1, 'Mary': 1, 'too': 1, '.': 1})\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "sentence = 'John likes to watch movies, Mary likes movies too.'\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "bow = Counter(tokens)\n",
    "\n",
    "print(f\"Bag of words:\\n{bow}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a634510",
   "metadata": {},
   "source": [
    "### 2) Языковые модели и перплексия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd5b63",
   "metadata": {},
   "source": [
    "Рассмотрим две фразы: \"Студенты пишут конспекты\" и \"Студенты пишут романы\". Если мы возьмем довольно большой корпус текста (например, все произведения русской литературы), вероятность встретить там первую фразу будет выше, чем вторую.  \n",
    "\n",
    "**Языковая модель** - это распределение вероятностей по всевозможным последовательностям слов.  \n",
    "\n",
    "Для последовательности слов длиной m, языковая модель позволяет оценить вероятность того, что эта последовательность встречается в тексте.  \n",
    "\n",
    "$$p_{sent} = P(t_{1},\\ldots , t_{m})$$  \n",
    "\n",
    "Простая униграмная модель не учитывает взаимное расположение слов. \n",
    "\n",
    "$$P_{\\text{uni}}(t_{1}t_{2}t_{3})=P(t_{1})P(t_{2})P(t_{3})$$\n",
    "\n",
    "Чтобы модель запомнила порядок слов, можно просто посчитать количество всех токенов, потом биграмм, триграмм и т.д., и сохранить эти значения. Например, биграмная модель вычисляет вероятность по формуле:  \n",
    "\n",
    "$$P_{\\text{bi}}(t_{1}t_{2}t_{3})=P(t_{1}|t_2)P(t_{2}|t_{3})$$\n",
    "\n",
    "Однако по мере увеличения объема корпуса, необходимая память для такой модели растет экспоненциально. \n",
    "\n",
    "На практике языковые модели генерируют вероятности путем *обучения* на больших текстовых корпусах, с использованием цепей Маркова, рекуррентных нейросетей или трансформеров. Продвинутые модели дают ненулевую вероятность даже для тех семантически и синтаксически допустимых последовательностей, которых не было в обучающей выборке. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d6409a",
   "metadata": {},
   "source": [
    "Более простая задача для языковой модели - предсказание следующего слова в заданном контексте. \n",
    "\n",
    "$$P(t_{n}|t_{n-1}, .. t_{1})$$\n",
    "\n",
    "Например, такую работу выполняет клавиатура при наборе сообщений на мобильном телефоне, предлагая три самых вероятных слова.  \n",
    "\n",
    "Распределение вероятности, предсказанное моделью, и распределение слов в корпусе, отличаются друг от друга. Если в тексте встречались фразы \"студенты пишут картины\", \"студенты пишут зачет\", \"студенты пишут конспекты\" (2 раза)  то распределение вероятностей последнего слова в фразе будет {'картины' - 0.25, 'зачет'-0.25, 'конспекты'-0.5}. Предсказанные вероятности для хорошей и плохой языковой модели представлены на рисунке.  \n",
    "\n",
    "<img src='imgs/lm.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd1ac7",
   "metadata": {},
   "source": [
    "Для того, чтобы оценить, насколько разные распределения вероятностей похожи друг на друга, используют понятие кросс-энтроии.\n",
    "\n",
    "$$\\mathrm {H} (p,q)=-\\sum _{x}p(x)\\,\\log q(x)$$\n",
    "\n",
    "где $p$ и $q$ - два разных распределения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335f5c8e",
   "metadata": {},
   "source": [
    "**Перплексия** языковой модели  — это способ оценки качества языковых моделей, вычисляется как 2 в степени энтропии.  \n",
    "\n",
    "$$PP(p):=2^{H(p,q)}=2^{-\\sum _{x}p(x)\\log _{2}q(x)}$$\n",
    "\n",
    "\n",
    "Перплексия может использоваться для сравнения качества статистических моделей. Низкий показатель перплексии указывает на то, что распределение вероятности хорошо предсказывает выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349c48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "lm = MLE(2)\n",
    "text = ['студенты пишут картины'.split(),\n",
    "        'студенты пишут зачет'.split(),\n",
    "        'студенты пишут конспекты'.split(),\n",
    "        'студенты пишут программы'.split()]\n",
    "\n",
    "train, vocab = padded_everygram_pipeline(2, text)\n",
    "lm.fit(train, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e1c2fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score('картины')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bc0fec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score('пишут', ['студенты'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569758de",
   "metadata": {},
   "source": [
    "### 3) Тематическое моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7667ad3",
   "metadata": {},
   "source": [
    "Знание того, о чем пишут люди, и понимание их проблем и мнений очень ценно для бизнеса. Очень трудно а иногда не возможно прочитать большие объемы теста человеком. Поэтому, требуется автоматизированный алгоритм, который может читать текстовые документы и автоматически выводить темы из текста.  \n",
    "\n",
    "**Тематическое моделирование** — способ построения модели коллекции текстовых документов, которая определяет, к каким темам относится каждый из документов.  \n",
    "**Тематическая модель** (topic model) коллекции текстовых документов определяет, к каким темам относится каждый документ и какие слова (термины) образуют каждую тему.  \n",
    "\n",
    "Интуитивно понимая, что документ относится к определённой теме, в документах, посвящённых одной теме, можно встретить некоторые слова чаще других. Например: «собака» и «кость» встречаются чаще в документах про собак, «кошки» и «молоко» будут встречаться в документах о котятах, предлоги «и» и «в» будут встречаться в обеих тематиках. Обычно документ касается нескольких тем в разных пропорциях, таким образом, документ в котором 10 % темы составляют кошки, а 90 % темы — собаки, можно предположить, что слов про собак в 9 раз больше. Тематическое моделирование отражает эту интуицию в математической структуре, которая позволяет на основании изучения коллекции документов и исследования частотных характеристик слов в каждом документе сделать вывод, что каждый документ — это некоторый баланс тем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccab8e5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Invalid requirement: 'gensim,'\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim, spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b148f087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: pyton: command not found\r\n"
     ]
    }
   ],
   "source": [
    "! pyton -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d5c2368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.corpora as corpora\n",
    "import gensim.models as gm\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "def remove_stopwords(texts, stop_words):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee855bc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"мужчина\" + 0.008*\"мама\" + 0.008*\"дело\" + 0.006*\"давать\" + 0.006*\"нужный\" + 0.006*\"наблюдать\" + 0.006*\"должный\" + 0.006*\"сама\" + 0.006*\"беременность\" + 0.006*\"отец\"'),\n",
       " (1,\n",
       "  '0.011*\"девушка\" + 0.009*\"отношение\" + 0.009*\"тыс\" + 0.009*\"рубль\" + 0.009*\"бывший\" + 0.007*\"мужик\" + 0.007*\"ребёнок\" + 0.007*\"знакомая\" + 0.007*\"говорить\" + 0.007*\"давать\"'),\n",
       " (2,\n",
       "  '0.012*\"семья\" + 0.012*\"любить\" + 0.010*\"ребёнок\" + 0.010*\"хотеть\" + 0.008*\"говорить\" + 0.008*\"время\" + 0.008*\"мочь\" + 0.008*\"коллега\" + 0.008*\"деньга\" + 0.008*\"гость\"'),\n",
       " (3,\n",
       "  '0.026*\"ребёнок\" + 0.010*\"девушка\" + 0.010*\"глаз\" + 0.007*\"бывший\" + 0.007*\"вопрос\" + 0.007*\"секс\" + 0.007*\"год\" + 0.007*\"получить\" + 0.007*\"жена\" + 0.005*\"женщина\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('texts/vk.txt') as f:\n",
    "    corpus = f.read().splitlines()\n",
    "\n",
    "sp_corpus = [simple_preprocess(doc) for doc in corpus if len(doc)>100]\n",
    "\n",
    "lemm_sp_corp = lemmatization(sp_corpus)\n",
    "\n",
    "ru_stopwords = stopwords.words(\"russian\")\n",
    "ru_stopwords += ['так', 'уже', 'очень', 'муж']\n",
    "clear_corpus= remove_stopwords(lemm_sp_corp, ru_stopwords)\n",
    "\n",
    "id2word = corpora.Dictionary(clear_corpus)\n",
    "\n",
    "ids_corpus = [id2word.doc2bow(text) for text in clear_corpus]\n",
    "\n",
    "lda_model = gm.ldamodel.LdaModel(corpus=ids_corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=4, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eff05a",
   "metadata": {},
   "source": [
    "### Задание:\n",
    "Подберите свой корпус текста для тематического моделирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85898beb",
   "metadata": {},
   "source": [
    "- https://webdevblog.ru/tematicheskoe-modelirovanie-s-pomoshhju-gensim-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
